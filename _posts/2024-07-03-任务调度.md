---
layout: post
title:  任务调度
category: kernel
description: hostboot上的任务管理
---

# task cpu/thread SMT SLB/TLB
cpu对应物理上的thread，实际上一个对应图中的IFB（instruction fetch buffer），更为直接的是一个物理thread有一对SLB/TLB
![](/assets/img/2024-07-04-13-34-59.png)

POWER8等现代处理器是支持SMT（Simultaneous Multithreading）模式的，在x86上是超线程，POWER8支持ST/SMT4/SMT8模式，是啥意思呢？  
就是一个物理核心core可以支持多个物理线程运行，目的还是为了榨干core的性能，所以也并不是物理线程越多越好，比如IO操作这种物理线程再多限制的瓶颈还是IO操作，core的SMT模式是可以配置的，但是物理core是早就生产好了的，所以POWER8最多可以支持SMT8，所以在SMT4的时候就有一半的SLB/TLB是空闲的:frog:

软件所谓的多线程，实际上应该是多任务，任务可以有很多，在stack不超过限制的情况下甚至可以很多很多任务，任务的执行是要在物理线程上的。物理线程是有限的，所以要有一种管理策略来让有限的线程让任务得以“合适”地运行。这个管理策略就是调度器，可见调度器应该是cpu的成员，但是core上应该只有一个调度器。所谓“合适”是相对的，比如RTOS强调实时性，就需要让高优先级的任务能够打断低优先级的执行，而linux是要让多任务“平等”执行，就有了各种策略，因为“平等”也是相对的:frog:

# 初始化
先从CpuManager的init开始，现在的代码都是在物理线程thread0上，因为只有thread-0能跑到main函数，初始化函数
```c++
void CpuManager::init()
{
    // For the initial boot we only want to set up CPU objects for the threads
    // on this core.  Otherwise we waste memory with kernel / idle task stacks.
    //
    // As long as the CPU object pointer is NULL, the start.S code won't
    // enter the kernel, so we skip initializing all the other CPUs for now.

    // Determine number of threads on this core.
    size_t threads = getThreadCount();

    // Set up CPU structure.
    cv_cpus[getPIR() / KERNEL_MAX_SUPPORTED_CPUS_PER_NODE] =
        new cpu_t*[KERNEL_MAX_SUPPORTED_CPUS_PER_NODE]();

    // Create CPU objects starting at the thread-0 for this core.
    size_t baseCpu = getCpuId() & ~(threads-1);
    for (size_t i = 0; i < threads; i++)
        Singleton<CpuManager>::instance().startCPU(i + baseCpu);
}
```
就是把当前core上的8个物理线程启动，调用startCPU，主要操作是：  
创建cpu结构体；  
创建调度器给cpu结构体；  
创建栈给cpu结构体；  
创建idle_task给cpu结构体；  
创建优先级队列delay_list给cpu结构体；  
代码就不贴了，主要目的就是创建cpu_t结构体，然后赋值初始化
```c++
struct cpu_t
{
    /** Stack to use while in kernel mode. */
    void* kernel_stack;

    /** Bottom of the kernel stack. */
    void* kernel_stack_bottom;

    /** ID of the CPU (PIR value) */
    cpuid_t cpu;

    struct
    {
        /** If the CPU is the master */
        bool master:1;

        /** If the CPU is active */
        bool active:1;

        /** If the CPU is winkled */
        bool winkled:1;

        /** Ensure alignment of master attribute for asm code. */
        uint64_t __reserved_master:29;
    } PACKED;

    /** Pointer to the scheduler for this CPU (may not be unique) */
    Scheduler* scheduler;

    /** Location for scheduler to store per-CPU data, currently used
     *  for the local run-queue for processor affinity.
     */
    void* scheduler_extra;

    /** Location for task delay-list, managed by TimeManager. */
    void* delay_list;

    /** Pointer to the idle task for this CPU */
    task_t* idle_task;

    /** XSCOM mutex to serialize access per CPU */
    mutex_t* xscom_mutex;

    /** counter for executePeriodics */
    size_t periodic_count;

    /** Sequence ID of CPU initialization. */
    uint64_t cpu_start_seqid;

};
```
## 创建调度器
```c++
cpu->scheduler = &Singleton<Scheduler>::instance();
```

这里用的是单例模式，**这个core上所有的cpu用的都是同一个调度器**，这也符合调度器的地位，调度器类的定义
```c++
class Scheduler
{
    public:
	friend class CpuManager;

	void addTask(task_t*);
    void addTaskMasterCPU(task_t*);

	void returnRunnable();
	void setNextRunnable();

    protected:
	Scheduler() :
		iv_taskList() {};
	~Scheduler() {};

    private:
        typedef Util::Locked::Queue<task_t, true, Spinlock> Runqueue_t;
        Runqueue_t iv_taskList;
};
```
其实就是维护一个运行队列 iv_taskList，提供了各种方法添加和执行任务（说的容易:frog:）  
简单说明一下这几个方法
1. addtask(task_t* t)
设置task的state为ready，task一般有三种状态：ready running end
把任务task t放到iv_tasklist中，当然需要考虑到亲和性，如果设置了亲和性，cpu_t结构体中还有scheduler_extra这个属性，就是一个单独的tasklist
```c++
    t->state = TASK_STATE_READY;

    if (t->cpu->idle_task != t)
    {
        // If task is pinned to this CPU, add to the per-CPU queue.
        if (0 != t->affinity_pinned)
        {
            // Allocate a per-CPU queue if this is the first pinning to CPU.
            Util::Lockfree::atomic_construct
                (reinterpret_cast<Runqueue_t**>(&t->cpu->scheduler_extra));

            // Insert into queue.
            static_cast<Runqueue_t*>(t->cpu->scheduler_extra)->insert(t);
        }
        // Not pinned, add to global run-queue.
        else
        {
            iv_taskList.insert(t);
        }
    }
```
2. addTaskMasterCPU(task_t* t)
   向master cpu的scheduler_extra添加task，这种需要亲和性的task不能放到调度器的tasklist，而是放到cpu的scheduler_extra，相当于每个cpu都有一个**独立的**亲和性相关的任务队列

3. returnRunnable()
   这个接口用于主动调度，sleep，把当前sleep的任务放到tasklist
   调用addtask，用getCurrentTask读寄存器SPRG3来获取当前cpu的task，然后调用addtask
```c++
    this->addTask(TaskManager::getCurrentTask());
```

4. setNextRunnable()
   从当前cpu的scheduler_extra、tasklist、或者idletask(这三者是有优先顺序的)，获取一个task然后给定时器设定时间片，把任务给到当前cpu
   ```c++
   //关键代码
   t = iv_taskList.remove();
   setDEC(TimeManager::getTimeSliceCount());// 调用mtdec
   TaskManager::setCurrentTask(t);
   ```
   这个接口也是用于主动调度，returnRunnable是把当前task放到tasklist，相当于保存上下文，setNextRunnable是获取下一个可执行的task给到CPU，相当于是执行下一个任务  
   比如TaskYield
   ```c++
    void TaskYield(task_t* t)
    {
        Scheduler* s = t->cpu->scheduler;
        s->returnRunnable();
        s->setNextRunnable();

        // This call prevents a live-lock situation.
        CpuManager::executePeriodics(CpuManager::getCurrentCPU());
    }
   ```
再比如sleep
```c++
void TimeNanosleep(task_t* t)
{
    TimeManager::delayTask(t, TASK_GETARG0(t), TASK_GETARG1(t));
    TASK_SETRTN(t, 0);

    t->cpu->scheduler->setNextRunnable();
}
```
yield和sleep还是有不同的，yield是让出当前的cpu给其他task，sleep是将task放到delaylist，到时间再拿出来运行，详细的没仔细看:frog:  
此外，taskyield还会执行周期性任务其中包括：  
定期的pagetable刷新；
内存的碎片的整理，比如对于iv_heap当中的bucket里面的内存页使用然后返还之后的碎片的整理；  
定期执行delaylist当中的任务；  

sleep和taskyield都是主动让出CPU，算是主动调度，当然，就算task不想让出，也会被让出，这就是定时器DEC的作用，DEC是一个32位的counter，倒计时归0的时候会触发Decrementer exception，表示时间片用尽了，这个exception有对应的中断向量0x800对应函数是
```c++
void kernel_execute_decrementer()
{
    cpu_t* c = CpuManager::getCurrentCPU();
    Scheduler* s = c->scheduler;
    TimeManager::checkReleaseTasks(s);

    task_t* current_task = TaskManager::getCurrentTask();

    CpuManager::executePeriodics(c);

    if (current_task == TaskManager::getCurrentTask())
    {
        s->returnRunnable();
        s->setNextRunnable();
    }
}
```
跟taskYield类似，只不过是先执行周期性任务然后再让出CPU

## 给cpu创建stack
```c++
        const size_t kernel_page_count = 4;
        const size_t kernel_page_offset = kernel_page_count * PAGESIZE - 8 * sizeof(uint64_t);
        cpu->kernel_stack_bottom = PageManager::allocatePage(kernel_page_count);
        cpu->kernel_stack = reinterpret_cast<void*>(
            reinterpret_cast<uintptr_t>(cpu->kernel_stack_bottom) +
            kernel_page_offset);
```
stack大小是4个page，从kernel的iv_heap当中allocate4个page，所以说堆和栈只是使用上有些不同而已:frog:
![](/assets/img/2024-07-04-16-19-28.png)

## 给cpu创建idletask
```c++
cpu->idle_task = TaskManager::createIdleTask();
```
所谓的启动cpu，要让cpu有任务，没有任务就创建空闲任务，ideletask就是执行一个死循环，内容是降低线程优先级然后nap()。创建这里使用了taskManager的createTask方法

### TaskManager::createTask
所谓的task，就是“上下文”context
```c++
    task_t* task = new task_t();

    task->tid = this->getNextTid();

    // Set NIP to be userspace_task_entry stub and GPR4 to be the
    // function pointer for the desired task entry point.
    task->context.nip = reinterpret_cast<void*>(&userspace_task_entry);
    task->context.gprs[4] = reinterpret_cast<uint64_t>(t);

    // Set up LR to be the entry point for task_end_stub in case a task
    // 'returns' from its entry point.
    task->context.lr = reinterpret_cast<uint64_t>(&task_end_stub);

    // Set up GRP[13] as task structure reserved.
    task->context.gprs[13] = (uint64_t)task;

    // Set up argument.
    task->context.gprs[3] = (uint64_t) p;

    // Setup stack.
    if (withStack)
    {
        task->context.stack_ptr = StackSegment::createStack(task->tid);
        task->context.gprs[1] =
            reinterpret_cast<uint64_t>(task->context.stack_ptr);
    }
    else
    {
	task->context.stack_ptr = NULL;
        task->context.gprs[1] = NULL;
    }
```
这里就是根据ABI的规范，把通用寄存器写上规定的东西，当然这个通用寄存器指的是软件上下文context的内容，调度的时候会写到相应的通用寄存器。  
另外这里如果需要有stack的话，还会在stacksegment创建一个stack block大小是256k，并设置物理页，并且设置allocate_from_zero，也就是需要分配物理页
```c++
l_block->setPhysicalPage(i, 0, WRITABLE | ALLOCATE_FROM_ZERO);
```

## 初始化timeManager
这里就做了一件事，给cpu创建delay_list，这个delay_list的作用在上面的sleep介绍过了，又能串起来了:frog:
关于这个详细的暂时先不看了……

## master CPU
创建完所有的cpu结构体之后，其实只有主线程（master cpu）在运行，其它的线程并没有运行，主线程既然在运行了就需要设定当前的时间片
```c++
    if (currentCPU)
    {
        setDEC(TimeManager::getTimeSliceCount());
        activateCPU(getCpu(i));
    }
```

然后调用CpuManager::actiateCPU，这块设定cpu_t结构体中active属性为true
```c++
i_cpu->active = false;
```
这就是启动cpu了，  
设定物理线程的一些属性，设定了LPCR寄存器，表示当前线程是因为什么被唤醒的，设定RPR寄存器，优先级相关，
到这为止其实还是**只有master thread在跑**，其它thread想要跑起来要等smp_slave_main当中的init_slave_smp运行，smp_slave_main要等自旋锁kernel_other_thread_spinlock=1，也就是主线程已经创建完了init_main 任务，**并把任务给到了主线程**，然后其它线程才会跑smp_slave_main，开始跑这个不代表cpu就active了，要给cpu_t结构体中active赋值了才算:frog: